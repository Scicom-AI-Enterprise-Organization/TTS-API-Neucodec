services:
  tts-engine:
    image: vllm/vllm-openai:v0.11.0
    ipc: host
    shm_size: 10.24gb
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: [gpu]
    container_name: tts-engine
    command:
      - --dtype 
      - bfloat16
      - --model
      - ${STT_MODEL:-Scicom-intl/Multilingual-TTS-1.7B-Base}
      - --port
      - "9093"
      - --gpu-memory-utilization 
      - ${GPU_MEM_UTIL:-0.7}
      - --max-model-len
      - "4096"
      - -O.cudagraph_mode=FULL_AND_PIECEWISE
      - --served-model-name 
      - TTS-model
    volumes:
      - "~/.cache/huggingface:/root/.cache/huggingface"
    ports:
      - "9093:9093"
    networks: ["tts-network"]

networks:
  tts-network:
    external: true